{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10066661,"sourceType":"datasetVersion","datasetId":6204149}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:07.718524Z","iopub.execute_input":"2024-12-06T11:43:07.718878Z","iopub.status.idle":"2024-12-06T11:43:07.722942Z","shell.execute_reply.started":"2024-12-06T11:43:07.718849Z","shell.execute_reply":"2024-12-06T11:43:07.722038Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install vit-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:07.731168Z","iopub.execute_input":"2024-12-06T11:43:07.731426Z","iopub.status.idle":"2024-12-06T11:43:17.508083Z","shell.execute_reply.started":"2024-12-06T11:43:07.731401Z","shell.execute_reply":"2024-12-06T11:43:17.507142Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting vit-pytorch\n  Downloading vit_pytorch-1.8.9-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting einops>=0.7.0 (from vit-pytorch)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.10 in /opt/conda/lib/python3.10/site-packages (from vit-pytorch) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from vit-pytorch) (0.19.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->vit-pytorch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->vit-pytorch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->vit-pytorch) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10->vit-pytorch) (1.3.0)\nDownloading vit_pytorch-1.8.9-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops, vit-pytorch\nSuccessfully installed einops-0.8.0 vit-pytorch-1.8.9\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install pytorch-lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:17.509895Z","iopub.execute_input":"2024-12-06T11:43:17.510183Z","iopub.status.idle":"2024-12-06T11:43:25.788477Z","shell.execute_reply.started":"2024-12-06T11:43:17.510155Z","shell.execute_reply":"2024-12-06T11:43:25.787617Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.4.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.4.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.7)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:25.789936Z","iopub.execute_input":"2024-12-06T11:43:25.790229Z","iopub.status.idle":"2024-12-06T11:43:25.795048Z","shell.execute_reply.started":"2024-12-06T11:43:25.790201Z","shell.execute_reply":"2024-12-06T11:43:25.794246Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class PathfinderDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        image = Image.open(img_path).convert('L')  # Grayscale image\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:25.797563Z","iopub.execute_input":"2024-12-06T11:43:25.797888Z","iopub.status.idle":"2024-12-06T11:43:25.808816Z","shell.execute_reply.started":"2024-12-06T11:43:25.797860Z","shell.execute_reply":"2024-12-06T11:43:25.808029Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Data Module\nclass PathfinderDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_dir, batch_size=32):\n        super().__init__()\n        self.dataset_dir = dataset_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose([\n            transforms.Resize((32, 32)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))  # Normalize grayscale images\n        ])\n\n    def prepare_data(self):\n        # Load the metadata and create a data list\n        self.data_list = []\n        metadata_dir = os.path.join(self.dataset_dir, 'metadata')\n        # imgs_dir = os.path.join(self.dataset_dir, 'imgs')\n        for file_name in os.listdir(metadata_dir):\n            metadata_path = os.path.join(metadata_dir, file_name)\n            with open(metadata_path, 'r') as file:\n                for line in file:\n                    tokens = line.strip().split()\n                    img_rel_path = tokens[0] + \"/\" + tokens[1] # changed\n                    label = int(tokens[3])  # Assuming label is the fourth value\n                    img_path = os.path.join(self.dataset_dir, img_rel_path)\n                    self.data_list.append((img_path, label))\n\n    def setup(self, stage=None):\n        # Split the data into train, val, and test sets\n        dataset = PathfinderDataset(self.data_list, transform=self.transform)\n        train_size = int(0.8 * len(dataset))\n        val_size = int(0.1 * len(dataset))\n        test_size = len(dataset) - train_size - val_size\n        self.train_set, self.val_set, self.test_set = random_split(\n            dataset, [train_size, val_size, test_size])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:25.809852Z","iopub.execute_input":"2024-12-06T11:43:25.810101Z","iopub.status.idle":"2024-12-06T11:43:25.819991Z","shell.execute_reply.started":"2024-12-06T11:43:25.810078Z","shell.execute_reply":"2024-12-06T11:43:25.819350Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Python\nfrom vit_pytorch import ViT\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\n\nclass PathfinderViTModel(pl.LightningModule):\n    def __init__(self, learning_rate=1e-3):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.model = ViT(\n            image_size=32,\n            patch_size=4,\n            num_classes=2,\n            dim=128,\n            depth=6,\n            heads=8,\n            mlp_dim=256,\n            channels=1  # Grayscale images have 1 channel\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = F.cross_entropy(logits, labels)\n        preds = logits.argmax(dim=1)\n        acc = (preds == labels).float().mean()\n        self.log('train_loss', loss)\n        self.log('train_acc', acc, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = F.cross_entropy(logits, labels)\n        preds = logits.argmax(dim=1)\n        acc = (preds == labels).float().mean()\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n\n    def test_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = F.cross_entropy(logits, labels)\n        preds = logits.argmax(dim=1)\n        acc = (preds == labels).float().mean()\n        self.log('test_loss', loss)\n        self.log('test_acc', acc, prog_bar=True)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:25.821228Z","iopub.execute_input":"2024-12-06T11:43:25.821483Z","iopub.status.idle":"2024-12-06T11:43:25.846520Z","shell.execute_reply.started":"2024-12-06T11:43:25.821460Z","shell.execute_reply":"2024-12-06T11:43:25.845875Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/lra-pathfinder-32/pathfinder32/curv_contour_length_14'  # Update with your dataset path\ndata_module = PathfinderDataModule(dataset_dir, batch_size=32)\nmodel = PathfinderViTModel()\n\ntrainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)\nstart_time = time.time()\ntrainer.fit(model, data_module)\ntrain_time = time.time() - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:43:25.847578Z","iopub.execute_input":"2024-12-06T11:43:25.847888Z","iopub.status.idle":"2024-12-06T12:07:14.627541Z","shell.execute_reply.started":"2024-12-06T11:43:25.847854Z","shell.execute_reply":"2024-12-06T12:07:14.626618Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffeedc496bbb4b92afb0f33479776868"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9119cfb54d4c1fa11f4bd6b15b39d4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0be7e37eed084934b0da7353a048c4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85186848ec2842eaa88ca4cee88c5714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b37f4089092f4047b5f5ce2bc2362099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711f855bd5ba4f55be7795fb7878980c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c18957dac12f4a55bc40f86623799fc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e949eac649e4dbeb29461eb4e31f622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db586efee9744ef1ae5adb53d3fb4856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5d0cf31a714256bc800514aebd25f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd460ba37f94d019b7d520493257028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753551763b7d47e9ad4e7c484e30d596"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"print(trainer.callback_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:07:14.629159Z","iopub.execute_input":"2024-12-06T12:07:14.629664Z","iopub.status.idle":"2024-12-06T12:07:14.645051Z","shell.execute_reply.started":"2024-12-06T12:07:14.629618Z","shell.execute_reply":"2024-12-06T12:07:14.644324Z"}},"outputs":[{"name":"stdout","text":"{'train_loss': tensor(0.6925), 'train_acc': tensor(0.5312), 'val_loss': tensor(0.6934), 'val_acc': tensor(0.4927)}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"trainer.test(model, datamodule=data_module)\nprint(trainer.callback_metrics)\naccuracy = trainer.callback_metrics['test_acc']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:07:14.646072Z","iopub.execute_input":"2024-12-06T12:07:14.646411Z","iopub.status.idle":"2024-12-06T12:07:26.802503Z","shell.execute_reply.started":"2024-12-06T12:07:14.646371Z","shell.execute_reply":"2024-12-06T12:07:26.801604Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f67d634fdef54ab28de697879d53fab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5004500150680542    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6932177543640137    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5004500150680542     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6932177543640137     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"{'test_loss': tensor(0.6932), 'test_acc': tensor(0.5005)}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nefficiency = accuracy / (torch.log(torch.tensor(train_time)) * torch.log(torch.tensor(num_params)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:07:26.805459Z","iopub.execute_input":"2024-12-06T12:07:26.805773Z","iopub.status.idle":"2024-12-06T12:07:26.851065Z","shell.execute_reply.started":"2024-12-06T12:07:26.805742Z","shell.execute_reply":"2024-12-06T12:07:26.850202Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(\"\\Metrics:\")\nprint(f\"Time Taken: {train_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Number of Parameters: {num_params}\")\nprint(f\"Efficiency Score: {efficiency:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:07:26.852079Z","iopub.execute_input":"2024-12-06T12:07:26.852330Z","iopub.status.idle":"2024-12-06T12:07:26.857002Z","shell.execute_reply.started":"2024-12-06T12:07:26.852305Z","shell.execute_reply":"2024-12-06T12:07:26.856132Z"}},"outputs":[{"name":"stdout","text":"\\Metrics:\nTime Taken: 1428.65 seconds\nAccuracy: 0.5005\nNumber of Parameters: 1983650\nEfficiency Score: 0.0048\n","output_type":"stream"}],"execution_count":12}]}