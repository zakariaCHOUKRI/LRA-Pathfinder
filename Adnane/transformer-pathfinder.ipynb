{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:36:35.241656Z","iopub.execute_input":"2024-12-08T13:36:35.242576Z","iopub.status.idle":"2024-12-08T13:36:35.247910Z","shell.execute_reply.started":"2024-12-08T13:36:35.242527Z","shell.execute_reply":"2024-12-08T13:36:35.246952Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class PathfinderDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        image = Image.open(img_path).convert('L')  # Grayscale image\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n    def collate_fn(self, batch):\n        # Custom collate function to ensure consistent tensor shapes\n        images, labels = zip(*batch)\n        images = torch.stack(list(images))\n        labels = torch.tensor(labels)\n        return images, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:36:35.254670Z","iopub.execute_input":"2024-12-08T13:36:35.254949Z","iopub.status.idle":"2024-12-08T13:36:35.261903Z","shell.execute_reply.started":"2024-12-08T13:36:35.254923Z","shell.execute_reply":"2024-12-08T13:36:35.261121Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class PathfinderDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_dir, batch_size=32):\n        super().__init__()\n        self.dataset_dir = dataset_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose([\n            transforms.Resize((32, 32)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))  # Normalize grayscale images\n        ])\n\n    def prepare_data(self):\n        # Load the metadata and create a data list\n        self.data_list = []\n        metadata_dir = os.path.join(self.dataset_dir, 'metadata')\n        for file_name in os.listdir(metadata_dir):\n            metadata_path = os.path.join(metadata_dir, file_name)\n            with open(metadata_path, 'r') as file:\n                for line in file:\n                    tokens = line.strip().split()\n                    img_rel_path = tokens[0] + \"/\" + tokens[1]\n                    label = int(tokens[3])  # Assuming label is the fourth value\n                    img_path = os.path.join(self.dataset_dir, img_rel_path)\n                    self.data_list.append((img_path, label))\n\n    def setup(self, stage=None):\n        # Split the data into train, val, and test sets\n        dataset = PathfinderDataset(self.data_list, transform=self.transform)\n        train_size = int(0.8 * len(dataset))\n        val_size = int(0.1 * len(dataset))\n        test_size = len(dataset) - train_size - val_size\n        self.train_set, self.val_set, self.test_set = random_split(\n            dataset, [train_size, val_size, test_size])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4, collate_fn=self.train_set.dataset.collate_fn)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=4, collate_fn=self.val_set.dataset.collate_fn)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=4, collate_fn=self.test_set.dataset.collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:36:35.265500Z","iopub.execute_input":"2024-12-08T13:36:35.265806Z","iopub.status.idle":"2024-12-08T13:36:35.279071Z","shell.execute_reply.started":"2024-12-08T13:36:35.265771Z","shell.execute_reply":"2024-12-08T13:36:35.278198Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=1024):\n        super().__init__()\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n        pe = torch.zeros(max_len, d_model)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:x.size(1)].unsqueeze(0)\n\nclass PathfinderTransformer(pl.LightningModule):\n    def __init__(self, d_model=256, nhead=8, num_layers=4, dim_feedforward=1024, dropout=0.1):\n        super().__init__()\n        \n        # Initial convolution layers to reduce spatial dimensions and extract features\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, d_model, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(d_model)\n        )\n        \n        # Flatten and positional encoding\n        self.pos_encoder = PositionalEncoding(d_model)\n        \n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, \n            nhead=nhead, \n            dim_feedforward=dim_feedforward, \n            dropout=dropout,\n            activation='relu'\n        )\n        self.transformer_encoder = nn.TransformerEncoder(\n            encoder_layer, \n            num_layers=num_layers\n        )\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 2)\n        )\n        \n        # Metrics\n        self.train_accuracy = torchmetrics.Accuracy(task='binary')\n        self.val_accuracy = torchmetrics.Accuracy(task='binary')\n        self.test_accuracy = torchmetrics.Accuracy(task='binary')\n        \n        # Loss function\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        # Ensure input is 4D (batch, channels, height, width)\n        if x.dim() == 2:\n            # If input is 2D, assume it's (batch, sequence)\n            # Reshape to (batch, channels, height, width)\n            x = x.view(-1, 1, 32, 32)\n        \n        # Extract features from input image\n        x = self.feature_extractor(x)\n        \n        # Reshape to sequence\n        x = x.flatten(2)  # (batch, channels, sequence_length)\n        x = x.permute(2, 0, 1)  # (sequence_length, batch, channels)\n        \n        # Add positional encoding\n        x = self.pos_encoder(x)\n        \n        # Pass through transformer encoder\n        x = self.transformer_encoder(x)\n        \n        # Global average pooling over sequence\n        x = x.mean(dim=0)\n        \n        # Classification\n        return self.classifier(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        \n        # Log accuracy\n        preds = torch.argmax(logits, dim=1)\n        self.train_accuracy(preds, y)\n        \n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_accuracy', self.train_accuracy, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        \n        # Log accuracy\n        preds = torch.argmax(logits, dim=1)\n        self.val_accuracy(preds, y)\n        \n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_accuracy', self.val_accuracy, prog_bar=True)\n        \n        return loss\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        \n        # Log accuracy\n        preds = torch.argmax(logits, dim=1)\n        self.test_accuracy(preds, y)\n        \n        self.log('test_loss', loss, prog_bar=True)\n        self.log('test_accuracy', self.test_accuracy, prog_bar=True)\n        \n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n            self.parameters(), \n            lr=1e-3, \n            weight_decay=1e-5\n        )\n        \n        # Learning rate scheduler\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, \n            mode='min', \n            factor=0.5, \n            patience=3, \n            verbose=True\n        )\n        \n        return {\n            'optimizer': optimizer,\n            'lr_scheduler': {\n                'scheduler': scheduler,\n                'monitor': 'val_loss'\n            }\n        }\n\n# Example of how to use the model\ndef train_pathfinder_model(dataset_dir):\n    # Set up data module\n    data_module = PathfinderDataModule(\n        dataset_dir=dataset_dir, \n        batch_size=32\n    )\n    \n    # Initialize model\n    model = PathfinderTransformer(\n        d_model=256, \n        nhead=8, \n        num_layers=4, \n        dim_feedforward=1024, \n        dropout=0.1\n    )\n    \n    # Initialize Lightning Trainer\n    trainer = pl.Trainer(\n        max_epochs=50,\n        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n        devices=1 if torch.cuda.is_available() else None,\n        precision=16 if torch.cuda.is_available() else 32,\n        callbacks=[\n            pl.callbacks.EarlyStopping(\n                monitor='val_loss', \n                patience=10, \n                mode='min'\n            ),\n            pl.callbacks.ModelCheckpoint(\n                monitor='val_accuracy', \n                mode='max', \n                save_top_k=1\n            )\n        ]\n    )\n    \n    # Train the model\n    start_time = time.time()\n    trainer.fit(model, data_module)\n    train_time = time.time() - start_time\n\n    print(trainer.callback_metrics)\n    \n    # Test the model\n    trainer.test(model, data_module)\n    print(trainer.callback_metrics)\n    accuracy = trainer.callback_metrics['test_accuracy']\n\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    efficiency = accuracy / (torch.log(torch.tensor(train_time)) * torch.log(torch.tensor(num_params)))\n\n    \n    return model, trainer, train_time, accuracy, num_params, efficiency","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:36:35.383922Z","iopub.execute_input":"2024-12-08T13:36:35.384181Z","iopub.status.idle":"2024-12-08T13:36:35.403378Z","shell.execute_reply.started":"2024-12-08T13:36:35.384148Z","shell.execute_reply":"2024-12-08T13:36:35.402523Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/lra-pathfinder-32/pathfinder32/curv_contour_length_14'  # Update with your dataset path\n\nmodel, trainer, train_time, accuracy, num_params, efficiency = train_pathfinder_model(dataset_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:36:35.405062Z","iopub.execute_input":"2024-12-08T13:36:35.405431Z","iopub.status.idle":"2024-12-08T14:25:33.287146Z","shell.execute_reply.started":"2024-12-08T13:36:35.405395Z","shell.execute_reply":"2024-12-08T14:25:33.286140Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc9eb5c91c84f0490c37c35186ac710"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c3ebe661f354c0eb927ffe946c15fca"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1deeb98600b34a3ab5b71dd9fc85d3c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b69e4204884349ceb5206e43684f5809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153ffd753cef4788b98f779e8b0e651c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0496c207cb458385b529eb9cdaeb63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a71a8d4b43c84df0bb7a91fb6a2d2006"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895e955c5c5c410593956b53ef6b45a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead5d037a31d41ca901efda12601dc5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb6c40e2d58945059aa6f4d71b6a7388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba31bf2fa4d24ceb89e850439d243651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f595a25ecab4849acf8c4c1fcdeac24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8da4c1db37446f97aba9fe98437360"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc9845af1f7f40e1a32cc1cbf4cd0ac8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4930a3d7223944c0846e17ec8add9bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbf61226c4342ea999c9196b001d926"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f417dad0a76341f38d5ab0332adf3052"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"282d81f5d890429b89db78956f65108b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6656b028c064faaa98de019d7c28e41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45c33c9d61124b9fac9a678175046965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98954a7992fe47f4a87ad92c1d48d0a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e95d018c48493fa45d9e26a1f1ade5"}},"metadata":{}},{"name":"stdout","text":"{'train_loss': tensor(0.6943), 'train_accuracy': tensor(0.3438), 'val_loss': tensor(0.6931), 'val_accuracy': tensor(0.4992)}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bdd5774326c4f869ee4ed3fa27f2679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5016999840736389    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.693102240562439    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5016999840736389     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.693102240562439     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"{'test_loss': tensor(0.6931), 'test_accuracy': tensor(0.5017)}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(\"\\Metrics:\")\nprint(f\"Time Taken: {train_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Number of Parameters: {num_params}\")\nprint(f\"Efficiency Score: {efficiency:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T14:25:33.288745Z","iopub.execute_input":"2024-12-08T14:25:33.289125Z","iopub.status.idle":"2024-12-08T14:25:33.294887Z","shell.execute_reply.started":"2024-12-08T14:25:33.289082Z","shell.execute_reply":"2024-12-08T14:25:33.293917Z"}},"outputs":[{"name":"stdout","text":"\\Metrics:\nTime Taken: 2926.44 seconds\nAccuracy: 0.5017\nNumber of Parameters: 3359426\nEfficiency Score: 0.0042\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}