{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10066661,"sourceType":"datasetVersion","datasetId":6204149}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nfrom PIL import Image\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport pytorch_lightning as pl\nimport torch\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\nfrom timm import create_model  # For DeiT","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:06.409820Z","iopub.execute_input":"2024-12-05T18:00:06.410226Z","iopub.status.idle":"2024-12-05T18:00:06.416026Z","shell.execute_reply.started":"2024-12-05T18:00:06.410190Z","shell.execute_reply":"2024-12-05T18:00:06.414615Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE = 32\nLEARNING_RATE = 2e-5\nEPOCHS = 5\nIMG_SIZE = 224  # Image size for DeiT\nDATASET_DIR = '/kaggle/input/lra-pathfinder-32/pathfinder32/curv_contour_length_14'  # Update as needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:07.684860Z","iopub.execute_input":"2024-12-05T18:00:07.685772Z","iopub.status.idle":"2024-12-05T18:00:07.690420Z","shell.execute_reply.started":"2024-12-05T18:00:07.685733Z","shell.execute_reply":"2024-12-05T18:00:07.689204Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Dataset Class\nclass PathfinderDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except (IOError, OSError, Image.DecompressionBombError, Image.UnidentifiedImageError):\n            new_idx = (idx + 1) % len(self.data)\n            return self[new_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:08.546497Z","iopub.execute_input":"2024-12-05T18:00:08.546860Z","iopub.status.idle":"2024-12-05T18:00:08.553688Z","shell.execute_reply.started":"2024-12-05T18:00:08.546831Z","shell.execute_reply":"2024-12-05T18:00:08.552600Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data Module\nclass PathfinderDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_dir, batch_size=BATCH_SIZE):\n        super().__init__()\n        self.dataset_dir = dataset_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose([\n            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n            transforms.ToTensor(),\n        ])\n\n    def prepare_data(self):\n        self.data_list = []\n        metadata_dir = os.path.join(self.dataset_dir, 'metadata')\n        for file_name in os.listdir(metadata_dir):\n            metadata_path = os.path.join(metadata_dir, file_name)\n            with open(metadata_path, 'r') as file:\n                for line in file:\n                    tokens = line.strip().split()\n                    img_rel_path = tokens[0] + \"/\" + tokens[1]\n                    label = int(tokens[3])\n                    img_path = os.path.join(self.dataset_dir, img_rel_path)\n                    self.data_list.append((img_path, label))\n\n    def setup(self, stage=None):\n        dataset = PathfinderDataset(self.data_list, transform=self.transform)\n        train_size = int(0.8 * len(dataset))\n        val_size = int(0.1 * len(dataset))\n        test_size = len(dataset) - train_size - val_size\n        self.train_set, self.val_set, self.test_set = random_split(dataset, [train_size, val_size, test_size])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:09.237219Z","iopub.execute_input":"2024-12-05T18:00:09.238012Z","iopub.status.idle":"2024-12-05T18:00:09.249607Z","shell.execute_reply.started":"2024-12-05T18:00:09.237971Z","shell.execute_reply":"2024-12-05T18:00:09.248377Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Initialize Data Module\ndata_module = PathfinderDataModule(DATASET_DIR)\ndata_module.prepare_data()\ndata_module.setup()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:09.875569Z","iopub.execute_input":"2024-12-05T18:00:09.875914Z","iopub.status.idle":"2024-12-05T18:00:12.145375Z","shell.execute_reply.started":"2024-12-05T18:00:09.875886Z","shell.execute_reply":"2024-12-05T18:00:12.143870Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize DeiT model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = create_model('deit_small_patch16_224', pretrained=True, num_classes=2)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:12.147431Z","iopub.execute_input":"2024-12-05T18:00:12.149487Z","iopub.status.idle":"2024-12-05T18:00:14.102687Z","shell.execute_reply.started":"2024-12-05T18:00:12.149432Z","shell.execute_reply":"2024-12-05T18:00:14.101617Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe35a27e1d2f45da87a8e4ac95889200"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"VisionTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (patch_drop): Identity()\n  (norm_pre): Identity()\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (1): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (2): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (3): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (4): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (5): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (6): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (7): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (8): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (9): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (10): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (11): Block(\n      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=384, out_features=384, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n  )\n  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n  (fc_norm): Identity()\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=384, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def train_model(model, train_loader, optimizer, loss_fn, epochs=EPOCHS):\n    model.train()\n    start_time = time.time()\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        total_loss = 0\n        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n    end_time = time.time()\n    return end_time - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:14.103980Z","iopub.execute_input":"2024-12-05T18:00:14.104332Z","iopub.status.idle":"2024-12-05T18:00:14.111887Z","shell.execute_reply.started":"2024-12-05T18:00:14.104300Z","shell.execute_reply":"2024-12-05T18:00:14.110640Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def evaluate_model(model, test_loader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=-1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    return accuracy, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:14.114288Z","iopub.execute_input":"2024-12-05T18:00:14.114642Z","iopub.status.idle":"2024-12-05T18:00:14.126242Z","shell.execute_reply.started":"2024-12-05T18:00:14.114609Z","shell.execute_reply":"2024-12-05T18:00:14.124962Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Train and Evaluate\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ntrain_loader = data_module.train_dataloader()\ntest_loader = data_module.test_dataloader()\n\ntrain_time = train_model(model, train_loader, optimizer, loss_fn, epochs=EPOCHS)\naccuracy, f1 = evaluate_model(model, test_loader)\n\n# Calculate number of parameters\nnum_params = sum(p.numel() for p in model.parameters())\n\n# Calculate efficiency score\nefficiency = accuracy / (torch.log(torch.tensor(train_time)) * torch.log(torch.tensor(num_params)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T18:00:14.127407Z","iopub.execute_input":"2024-12-05T18:00:14.127756Z","iopub.status.idle":"2024-12-05T20:49:25.477731Z","shell.execute_reply.started":"2024-12-05T18:00:14.127725Z","shell.execute_reply":"2024-12-05T20:49:25.476655Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 5000/5000 [33:25<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.6940\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 5000/5000 [33:31<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.6935\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 5000/5000 [33:31<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.6587\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 5000/5000 [33:36<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.5638\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 5000/5000 [33:39<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.4368\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 625/625 [01:26<00:00,  7.24it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Print metrics\nprint(\"\\nTraining Metrics:\")\nprint(f\"Time Taken: {train_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Number of Parameters: {num_params}\")\nprint(f\"Efficiency Score: {efficiency.item():.4f}\")\n\n# Save the model\ntorch.save(model.state_dict(), 'deit_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:49:25.479305Z","iopub.execute_input":"2024-12-05T20:49:25.479625Z","iopub.status.idle":"2024-12-05T20:49:25.631951Z","shell.execute_reply.started":"2024-12-05T20:49:25.479593Z","shell.execute_reply":"2024-12-05T20:49:25.630887Z"}},"outputs":[{"name":"stdout","text":"\nTraining Metrics:\nTime Taken: 10064.90 seconds\nAccuracy: 0.7883\nNumber of Parameters: 21666434\nEfficiency Score: 0.0051\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}