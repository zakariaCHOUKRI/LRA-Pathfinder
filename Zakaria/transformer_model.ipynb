{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10066661,"sourceType":"datasetVersion","datasetId":6204149}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom sklearn.metrics import accuracy_score\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:37:57.859513Z","iopub.execute_input":"2024-12-05T13:37:57.859827Z","iopub.status.idle":"2024-12-05T13:38:04.473990Z","shell.execute_reply.started":"2024-12-05T13:37:57.859797Z","shell.execute_reply":"2024-12-05T13:38:04.473335Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE = 32\nLEARNING_RATE = 2e-5\nEPOCHS = 5\nIMG_SIZE = 32  # 32x32 grayscale images\nDATASET_DIR = '/kaggle/input/lra-pathfinder-32/pathfinder32/curv_contour_length_14'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.475307Z","iopub.execute_input":"2024-12-05T13:38:04.475708Z","iopub.status.idle":"2024-12-05T13:38:04.479890Z","shell.execute_reply.started":"2024-12-05T13:38:04.475679Z","shell.execute_reply":"2024-12-05T13:38:04.479033Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Dataset Class\nclass PathfinderDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path).convert('L')  # Grayscale\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            new_idx = (idx + 1) % len(self.data)\n            return self[new_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.480895Z","iopub.execute_input":"2024-12-05T13:38:04.481152Z","iopub.status.idle":"2024-12-05T13:38:04.494007Z","shell.execute_reply.started":"2024-12-05T13:38:04.481126Z","shell.execute_reply":"2024-12-05T13:38:04.493234Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Data Module\nclass PathfinderDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_dir, batch_size=BATCH_SIZE):\n        super().__init__()\n        self.dataset_dir = dataset_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose([\n            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n            transforms.ToTensor(),\n        ])\n\n    def prepare_data(self):\n        self.data_list = []\n        metadata_dir = os.path.join(self.dataset_dir, 'metadata')\n        for file_name in os.listdir(metadata_dir):\n            metadata_path = os.path.join(metadata_dir, file_name)\n            with open(metadata_path, 'r') as file:\n                for line in file:\n                    tokens = line.strip().split()\n                    img_rel_path = tokens[0] + '/' + tokens[1]\n                    label = int(tokens[3])\n                    img_path = os.path.join(self.dataset_dir, img_rel_path)\n                    self.data_list.append((img_path, label))\n\n    def setup(self, stage=None):\n        dataset = PathfinderDataset(self.data_list, transform=self.transform)\n        train_size = int(0.8 * len(dataset))\n        val_size = int(0.1 * len(dataset))\n        test_size = len(dataset) - train_size - val_size\n        self.train_set, self.val_set, self.test_set = random_split(dataset, [train_size, val_size, test_size])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.496470Z","iopub.execute_input":"2024-12-05T13:38:04.496828Z","iopub.status.idle":"2024-12-05T13:38:04.505812Z","shell.execute_reply.started":"2024-12-05T13:38:04.496787Z","shell.execute_reply":"2024-12-05T13:38:04.505031Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Transformer Model\nclass SequenceTransformer(nn.Module):\n    def __init__(self, img_size, num_classes):\n        super().__init__()\n        self.img_size = img_size\n        self.num_patches = img_size * img_size\n        self.patch_dim = 1\n        self.embedding_dim = 64\n\n        self.embedding = nn.Linear(self.patch_dim, self.embedding_dim)\n        self.transformer = nn.Transformer(\n            d_model=self.embedding_dim,\n            nhead=4,\n            num_encoder_layers=3\n        )\n        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        x = x.view(batch_size, -1, self.patch_dim)  # Flatten to sequence\n        x = self.embedding(x)\n        x = self.transformer(x, x)\n        x = x.mean(dim=1)  # Global average pooling\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.506876Z","iopub.execute_input":"2024-12-05T13:38:04.507127Z","iopub.status.idle":"2024-12-05T13:38:04.518541Z","shell.execute_reply.started":"2024-12-05T13:38:04.507102Z","shell.execute_reply":"2024-12-05T13:38:04.517755Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Initialize Model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SequenceTransformer(img_size=IMG_SIZE, num_classes=2).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.519633Z","iopub.execute_input":"2024-12-05T13:38:04.519897Z","iopub.status.idle":"2024-12-05T13:38:04.837231Z","shell.execute_reply.started":"2024-12-05T13:38:04.519873Z","shell.execute_reply":"2024-12-05T13:38:04.836523Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Training and Evaluation\ndef train_model(model, train_loader, optimizer, loss_fn, epochs):\n    print(\"Starting training...\")\n    model.train()\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        total_loss = 0\n        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n        print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.838348Z","iopub.execute_input":"2024-12-05T13:38:04.838693Z","iopub.status.idle":"2024-12-05T13:38:04.844834Z","shell.execute_reply.started":"2024-12-05T13:38:04.838655Z","shell.execute_reply":"2024-12-05T13:38:04.844034Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate_model(model, test_loader):\n    print(\"Evaluating model...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=-1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.845914Z","iopub.execute_input":"2024-12-05T13:38:04.846685Z","iopub.status.idle":"2024-12-05T13:38:04.854211Z","shell.execute_reply.started":"2024-12-05T13:38:04.846657Z","shell.execute_reply":"2024-12-05T13:38:04.853335Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data_module = PathfinderDataModule(DATASET_DIR)\ndata_module.prepare_data()\ndata_module.setup()\n\ntrain_loader = data_module.train_dataloader()\ntest_loader = data_module.test_dataloader()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nloss_fn = nn.CrossEntropyLoss()\n\nstart_time = time.time()\ntrain_model(model, train_loader, optimizer, loss_fn, EPOCHS)\ntrain_time = time.time() - start_time\n\naccuracy = evaluate_model(model, test_loader)\n\nnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nefficiency = accuracy / (torch.log(torch.tensor(train_time)) * torch.log(torch.tensor(num_params)))\n\nprint(\"\\nTraining Metrics:\")\nprint(f\"Time Taken: {train_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Number of Parameters: {num_params}\")\nprint(f\"Efficiency Score: {efficiency:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:38:04.855368Z","iopub.execute_input":"2024-12-05T13:38:04.856117Z","iopub.status.idle":"2024-12-05T16:28:18.378605Z","shell.execute_reply.started":"2024-12-05T13:38:04.856080Z","shell.execute_reply":"2024-12-05T16:28:18.377724Z"}},"outputs":[{"name":"stdout","text":"Starting training...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 5000/5000 [33:45<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.6945\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 5000/5000 [33:49<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.6937\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 5000/5000 [33:49<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.6935\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 5000/5000 [33:47<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.6934\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 5000/5000 [33:46<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.6934\nEvaluating model...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 625/625 [01:13<00:00,  8.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.5011\n\nTraining Metrics:\nTime Taken: 10138.11 seconds\nAccuracy: 0.5011\nNumber of Parameters: 2631490\nEfficiency Score: 0.0037\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}