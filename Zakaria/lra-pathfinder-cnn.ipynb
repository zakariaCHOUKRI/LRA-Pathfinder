{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10066661,"sourceType":"datasetVersion","datasetId":6204149}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport pytorch_lightning as pl\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\n# Dataset Class\nclass PathfinderDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except (IOError, OSError, Image.DecompressionBombError, Image.UnidentifiedImageError):\n            # If the image is corrupted, recursively fetch another sample\n            new_idx = (idx + 1) % len(self.data)  # Avoid index out of bounds\n            return self[new_idx]\n\n# Data Module\nclass PathfinderDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_dir, batch_size=32):\n        super().__init__()\n        self.dataset_dir = dataset_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize for MobileNetV2\n            transforms.ToTensor(),\n        ])\n\n    def prepare_data(self):\n        print(\"Preparing data...\")\n        self.data_list = []\n        metadata_dir = os.path.join(self.dataset_dir, 'metadata')\n        for file_name in os.listdir(metadata_dir):\n            metadata_path = os.path.join(metadata_dir, file_name)\n            with open(metadata_path, 'r') as file:\n                for line in file:\n                    tokens = line.strip().split()\n                    img_rel_path = tokens[0] + \"/\" + tokens[1]\n                    label = int(tokens[3])  # Assuming label is the fourth value\n                    img_path = os.path.join(self.dataset_dir, img_rel_path)\n                    self.data_list.append((img_path, label))\n        print(f\"Prepared {len(self.data_list)} data entries.\")\n\n    def setup(self, stage=None):\n        print(\"Setting up datasets...\")\n        dataset = PathfinderDataset(self.data_list, transform=self.transform)\n\n        train_size = int(0.8 * len(dataset))\n        val_size = int(0.1 * len(dataset))\n        test_size = len(dataset) - train_size - val_size\n        self.train_set, self.val_set, self.test_set = random_split(\n            dataset, [train_size, val_size, test_size])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=4)\n\n# Define Dataset Directory and Data Module\ndataset_dir = '/kaggle/input/lra-pathfinder-32/pathfinder32/curv_baseline'  # Update as needed\ndata_module = PathfinderDataModule(dataset_dir, batch_size=32)\n\n# Prepare Data\ndata_module.prepare_data()\ndata_module.setup()\n\n# Define Model\nprint(\"Initializing model...\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.mobilenet_v2(pretrained=True)  # Use MobileNetV2\nmodel.classifier[1] = torch.nn.Linear(model.last_channel, 2)  # Update for binary classification\nmodel.to(device)\n\n# Training Function\ndef train_model(model, train_loader, optimizer, loss_fn, epochs=5):\n    print(\"Starting training...\")\n    model.train()\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        total_loss = 0\n        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n\n# Evaluation Function\ndef evaluate_model(model, test_loader):\n    print(\"Evaluating model...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=-1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    return accuracy\n\n# Train and Evaluate\nprint(\"Training and evaluation begin...\")\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ntrain_loader = data_module.train_dataloader()\ntest_loader = data_module.test_dataloader()\n\ntrain_model(model, train_loader, optimizer, loss_fn, epochs=5)\nevaluate_model(model, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:59:19.836357Z","iopub.execute_input":"2024-12-03T20:59:19.837051Z"}},"outputs":[{"name":"stdout","text":"Preparing data...\nPrepared 200000 data entries.\nSetting up datasets...\nInitializing model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 110MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Training and evaluation begin...\nStarting training...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 5000/5000 [11:01<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.4293\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 5000/5000 [11:02<00:00,  7.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.1405\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 5000/5000 [11:03<00:00,  7.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.0991\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 5000/5000 [11:02<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.0758\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 5000/5000 [11:05<00:00,  7.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.0594\nEvaluating model...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 619/625 [00:51<00:00, 12.00it/s]","output_type":"stream"}],"execution_count":null}]}